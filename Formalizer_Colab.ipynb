{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Formalizer Colab",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiOx4dGRzXs4",
        "cellView": "form",
        "outputId": "f687a845-9c58-4520-f182-b4c8b467ba34"
      },
      "source": [
        "#@title Install libraries, imports and variables\n",
        "#@markdown Please \"Connect with Drive\" before proceeding\n",
        "#@markdown \n",
        "#@markdown Run only once\n",
        "\n",
        "import os\n",
        "\n",
        "\n",
        "if os.path.isdir(f'./drive/'):\n",
        "  %tensorflow_version 1.x\n",
        "  !pip install -q gpt-2-simple\n",
        "\n",
        "  print('Libraries installed...')\n",
        "\n",
        "  #import tensorflow\n",
        "  import gpt_2_simple as gpt2\n",
        "  from datetime import datetime\n",
        "  import numpy as np\n",
        "  import tensorflow as tf\n",
        "  import tensorflow_hub as hub\n",
        "  import gc\n",
        "\n",
        "  print('Imports finished...')\n",
        "\n",
        "  #tf.enable_eager_execution()\n",
        "  #tf.executing_eagerly()\n",
        "\n",
        "  formal_path = \"/content/drive/My Drive/Colab Notebooks/Corpus/model_frml_USE\"\n",
        "\n",
        "else:\n",
        "  print(\"Please Connect with Drive\")\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "#@markdown ____\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Requirement already satisfied: anvil-uplink in /usr/local/lib/python3.7/dist-packages (0.3.36)\n",
            "Requirement already satisfied: argparse in /usr/local/lib/python3.7/dist-packages (from anvil-uplink) (1.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from anvil-uplink) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from anvil-uplink) (0.16.0)\n",
            "Requirement already satisfied: ws4py in /usr/local/lib/python3.7/dist-packages (from anvil-uplink) (0.5.1)\n",
            "Libraries installed...\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "Imports finished...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4mq4F8V0Ldv",
        "cellView": "form",
        "outputId": "15dff8d9-74fe-4390-b9a0-43ce09ef8480"
      },
      "source": [
        "#@title Select run { run: \"auto\" }\n",
        "run_name = \"run1\" #@param {type:\"string\"}\n",
        "\n",
        "if not os.path.isdir(f'./checkpoint/{run_name}'):\n",
        "  print(f\"Copy checkpoint {run_name}...\")\n",
        "  gpt2.copy_checkpoint_from_gdrive(run_name=run_name)\n",
        "else:\n",
        "  print(f\"Checkpoint {run_name} already exist\")\n",
        "\n",
        "\n",
        "print('Starting TF sess...')\n",
        "tf.reset_default_graph()\n",
        "sess = gpt2.start_tf_sess(threads=-1)\n",
        "gpt2.load_gpt2(sess, run_name=run_name)\n",
        "print(f'TF sess {run_name} loaded')\n",
        "\n",
        "sess2 = tf.Session()\n",
        "\n",
        "with sess2.as_default():\n",
        "  embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-large/5\")\n",
        "\n",
        "sess2.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
        "\n",
        "def get_meaning_pres(a,b):\n",
        "  #sess2.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
        "  embeddings = embed(\n",
        "        [a] + b\n",
        "    )\n",
        "    \n",
        "  message_embeddings = sess2.run(embeddings)\n",
        "\n",
        "  return np.inner(message_embeddings[0],message_embeddings[1:])\n",
        "\n",
        "#@markdown ____\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checkpoint run1 already exist\n",
            "Starting TF sess...\n",
            "Loading checkpoint checkpoint/run1/model-2000\n",
            "INFO:tensorflow:Restoring parameters from checkpoint/run1/model-2000\n",
            "TF sess run1 loaded\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ridG5w3C2H27",
        "cellView": "form",
        "outputId": "62aac357-93d5-4f23-9f1b-74947ea3e04d"
      },
      "source": [
        "#@title Set variables { run: \"auto\" }\n",
        "\n",
        "#@markdown ```informal_input: max 300 characters```\n",
        "informal_input = \"im here but i dunno why\" #@param {type:\"string\"}\n",
        "if len(informal_input) > 300:\n",
        "  print('Input too long, triming...')\n",
        "  informal_input = informal_input[:300]\n",
        "\n",
        "#@markdown ```samples: range [1,10]```\n",
        "samples = 7 #@param {type:\"slider\", min:0, max:10, step:1} \n",
        "\n",
        "\n",
        "#@markdown ```temperature: range [0,1]```\n",
        "temperature = 0.7 #@param {type:\"slider\", min:0, max:1, step:0.05} \n",
        "\n",
        "#@markdown ```get_metrics: formality and meaning preservation```\n",
        "get_metrics = True #@param {type:\"boolean\"}\n",
        "\n",
        "print(f\"Input:\", informal_input)\n",
        "print(f\"Samples:\", samples)\n",
        "print(f\"Temperature:\", temperature)\n",
        "\n",
        "#@markdown ____\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: im here but i dunno why\n",
            "Samples: 7\n",
            "Temperature: 0.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdY8OGVN50lD",
        "cellView": "form",
        "outputId": "b2413752-aaf6-4200-c265-a13998177b84"
      },
      "source": [
        "#@title Run model \n",
        "#@markdown Run this cell to execute the transfer. It will take up to a minute the first time.\n",
        "#@markdown ____\n",
        "print('Generando...')\n",
        "arr = gpt2.generate(sess,\n",
        "            run_name = run_name,\n",
        "            length=300,\n",
        "            temperature=temperature,\n",
        "            prefix=f\"<|startoftext|>[Informal]{informal_input}\\n[Formal]\",\n",
        "            truncate = '<|endoftext|>',\n",
        "            nsamples=samples,\n",
        "            batch_size=samples,\n",
        "            include_prefix=False,\n",
        "            return_as_list=True)\n",
        "arr = list(set(arr))\n",
        "arr = [x.replace(\"[Formal]\",\"\").replace(\"[Informal]\",\"\").replace(\"<|startoftext|>\",\"\") for x in arr]\n",
        "\n",
        "if get_metrics:\n",
        "  mean_press = get_meaning_pres(informal_input,arr)\n",
        "\n",
        "print('Generado...\\n')\n",
        "\n",
        "print(f\"Input sentence: {informal_input}\")\n",
        "print('Outputs'.ljust(100),f'{\"Meaning Preservation\" if get_metrics else \"\"}'.ljust(10))\n",
        "for i in range(len(arr)):\n",
        "  print(arr[i].ljust(100),str(mean_press[i]).ljust(10))\n",
        "\n",
        "if get_metrics:\n",
        "  print('\\n\\n\\nCopy the following line to Formality Metric Notebook:')\n",
        "  print(arr)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generando...\n",
            "Generado...\n",
            "\n",
            "Input sentence: im here but i dunno why\n",
            "Outputs                                                                                              Meaning Preservation\n",
            "I am here, but I do not know why.                                                                    0.9121772 \n",
            "I am here, however I do not know why.                                                                0.8429709 \n",
            "I'm here, but I'm unsure why.                                                                        0.9717683 \n",
            "\n",
            "\n",
            "\n",
            "Copy the following line to Formality Metric Notebook:\n",
            "['I am here, but I do not know why.', 'I am here, however I do not know why.', \"I'm here, but I'm unsure why.\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSRw3tImJqpV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}